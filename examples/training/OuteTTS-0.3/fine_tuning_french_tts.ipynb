{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning OuteTTS for French TTS on Google Colab\n",
    "\n",
    "This notebook provides comprehensive steps for fine-tuning the OuteTTS model for French Text-to-Speech (TTS) using Google Colab. Follow the steps below to set up the environment, prepare the data, train the model, and evaluate the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup\n",
    "\n",
    "First, we need to set up the environment and install the necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "colab_type": "code",
    "id": "setup-environment"
   },
   "source": [
    "# Install necessary packages\n",
    "!pip install outetts\n",
    "!pip install torch torchaudio\n",
    "!pip install transformers\n",
    "!pip install polars\n",
    "!pip install loguru\n",
    "!pip install tqdm\n",
    "!pip install soundfile\n",
    "!pip install openai-whisper\n",
    "!pip install mecab-python3 unidic-lite\n",
    "!pip install uroman\n",
    "!pip install pygame\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Preparation\n",
    "\n",
    "Prepare your dataset for fine-tuning. Ensure your raw data is formatted as Parquet files with a `\"transcript\"` field of type string and an `\"audio\"` field containing audio bytes in `\"bytes\"`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "colab_type": "code",
    "id": "data-preparation"
   },
   "source": [
    "# Example script to process and prepare data\n",
    "import os\n",
    "import polars as pl\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from outetts.wav_tokenizer.audio_codec import AudioCodec\n",
    "from outetts.version.v2.prompt_processor import PromptProcessor\n",
    "from outetts.version.v2.alignment import CTCForcedAlignment\n",
    "import io\n",
    "from loguru import logger\n",
    "\n",
    "class DataCreation:\n",
    "    def __init__(self, model_tokenizer_path: str, audio_files_path: str, save_dir: str, save_len: int = 5000):\n",
    "        self.device = \"cuda\"\n",
    "        self.audio_codec = AudioCodec(device=self.device, load_decoder=False)\n",
    "        self.prompt_processor = PromptProcessor(model_tokenizer_path)\n",
    "        self.files = self.get_files(audio_files_path, \".parquet\")\n",
    "        self.ctc = CTCForcedAlignment(self.device)\n",
    "        self.save_dir = save_dir\n",
    "        self.save_len = save_len\n",
    "        self.save_id = 0\n",
    "        self.data = []\n",
    "\n",
    "    def get_files(self, folder_path, extension_filter=None):\n",
    "        if isinstance(extension_filter, str):\n",
    "            extension_filter = [extension_filter]\n",
    "        matching_files = []\n",
    "        for root, _, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                if extension_filter:\n",
    "                    if any(file.endswith(ext) for ext in extension_filter):\n",
    "                        matching_files.append(os.path.join(root, file))\n",
    "                else:\n",
    "                    matching_files.append(os.path.join(root, file))\n",
    "        return matching_files\n",
    "\n",
    "    def create_speaker(self, audio, transcript: str):\n",
    "        words = self.ctc.align(audio, transcript)\n",
    "        full_codes = self.audio_codec.encode(\n",
    "            self.audio_codec.convert_audio_tensor(\n",
    "                audio=torch.cat([i[\"audio\"] for i in words], dim=1),\n",
    "                sr=self.ctc.sample_rate\n",
    "            ).to(self.audio_codec.device)\n",
    "        ).tolist()\n",
    "        data = []\n",
    "        start = 0\n",
    "        for i in words:\n",
    "            end = int(round((i[\"x1\"] / self.ctc.sample_rate) * 75))\n",
    "            word_tokens = full_codes[0][0][start:end]\n",
    "            start = end\n",
    "            if not word_tokens:\n",
    "                word_tokens = [1]\n",
    "            data.append({\n",
    "                \"word\": i[\"word\"],\n",
    "                \"duration\": round(len(word_tokens) / 75, 2),\n",
    "                \"codes\": word_tokens\n",
    "            })\n",
    "        return {\n",
    "            \"text\": transcript,\n",
    "            \"words\": data,\n",
    "        }\n",
    "\n",
    "    def save(self):\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "        path = os.path.join(self.save_dir, f\"{self.save_id:06d}.parquet\")\n",
    "        logger.info(f\"Saving data: {path}\")\n",
    "        pl.DataFrame(self.data).write_parquet(path)\n",
    "        self.data = []\n",
    "        self.save_id += 1\n",
    "\n",
    "    def run(self):\n",
    "        for i in self.files:\n",
    "            df = pl.read_parquet(i)\n",
    "            for data in tqdm(df.iter_rows(named=True), total=len(df)):\n",
    "                try:\n",
    "                    transcript = data['transcript']\n",
    "                    audio = io.BytesIO(data['audio']['bytes'])\n",
    "                    speaker = self.create_speaker(audio, transcript)\n",
    "                    prompt = self.prompt_processor.get_training_prompt(speaker)\n",
    "                    self.data.append({\n",
    "                        'prompt': prompt,\n",
    "                    })\n",
    "                    if len(self.data) == self.save_len:\n",
    "                        self.save()\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"{e}\\n\\nOccasional exceptions are expected due to potential inaccuracies or issues in the audio files. This is normal and may not indicate a critical problem, but a high frequency of errors might suggest an underlying issue that needs attention.\")\n",
    "        if self.data:\n",
    "            self.save()\n",
    "\n",
    "# Example usage\n",
    "data_creator = DataCreation(\n",
    "    model_tokenizer_path=\"path/to/model/tokenizer\",\n",
    "    audio_files_path=\"path/to/audio/files\",\n",
    "    save_dir=\"path/to/save/processed/data\"\n",
    ")\n",
    "data_creator.run()\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Model Training\n",
    "\n",
    "Now, we will fine-tune the OuteTTS model using the prepared dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "colab_type": "code",
    "id": "model-training"
   },
   "source": [
    "from outetts import InterfaceHF, HFModelConfig\n",
    "\n",
    "# Define model configuration\n",
    "config = HFModelConfig(\n",
    "    model_path=\"OuteAI/OuteTTS-0.3-500M\",\n",
    "    language=\"fr\",\n",
    "    tokenizer_path=\"path/to/tokenizer\",\n",
    "    max_seq_length=4096,\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "# Initialize the model interface\n",
    "tts_interface = InterfaceHF(config)\n",
    "\n",
    "# Example training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in data_loader:\n",
    "        # Fine-tune the model with the batch data\n",
    "        tts_interface.train(batch)\n",
    "        # Save the model checkpoint\n",
    "        tts_interface.save_checkpoint(f\"checkpoint_{epoch}.pt\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model Evaluation\n",
    "\n",
    "Evaluate the fine-tuned model to ensure it performs well on French TTS."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "colab_type": "code",
    "id": "model-evaluation"
   },
   "source": [
    "# Example evaluation script\n",
    "from outetts import InterfaceHF, HFModelConfig\n",
    "\n",
    "# Define model configuration\n",
    "config = HFModelConfig(\n",
    "    model_path=\"path/to/fine-tuned/model\",\n",
    "    language=\"fr\",\n",
    "    tokenizer_path=\"path/to/tokenizer\",\n",
    "    max_seq_length=4096,\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "# Initialize the model interface\n",
    "tts_interface = InterfaceHF(config)\n",
    "\n",
    "# Example evaluation\n",
    "text = \"Bonjour, comment Ã§a va?\"\n",
    "output = tts_interface.generate(text)\n",
    "output.save(\"output.wav\")\n",
    "\n",
    "# Play the generated audio\n",
    "import IPython.display as ipd\n",
    "ipd.Audio(\"output.wav\")\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "fine_tuning_french_tts.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
