{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tuning OuteTTS for French TTS on Google Colab\n",
    "\n",
    "This notebook provides comprehensive steps for fine-tuning the OuteTTS model for French Text-to-Speech (TTS) using Google Colab. Follow the steps below to set up the environment, prepare the data, train the model, and evaluate the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup\n",
    "\n",
    "First, we need to set up the environment and install the necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "!pip install outetts torch torchaudio transformers polars loguru tqdm soundfile openai-whisper mecab-python3 unidic-lite uroman pygame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Preparation\n",
    "\n",
    "Prepare your dataset for fine-tuning. Ensure your raw data is formatted as Parquet files with a `\"transcript\"` field of type string and an `\"audio\"` field containing audio bytes in `\"bytes\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os
    import polars as pl
    import torch
    from tqdm import tqdm
    from outetts.wav_tokenizer.audio_codec import AudioCodec
    from outetts.version.v2.prompt_processor import PromptProcessor
    from outetts.version.v2.alignment import CTCForcedAlignment
    import io
    from loguru import logger

    class DataCreation:
        def __init__(self, model_tokenizer_path: str, audio_files_path: str, save_dir: str, save_frequency: int = 1000):
            self.device = \"cuda\"
            self.audio_codec = AudioCodec(device=self.device, load_decoder=False)
            self.prompt_processor = PromptProcessor(model_tokenizer_path)
            self.files = self.get_files(audio_files_path, \".parquet\")
            self.ctc = CTCForcedAlignment(self.device)
            self.save_dir = save_dir
            self.save_frequency = save_frequency
            self.items_processed = 0
            self.current_batch = []
            self.save_id = 0

        def get_files(self, folder_path, extension_filter=None):
            if isinstance(extension_filter, str):
                extension_filter = [extension_filter]
            matching_files = []
            for root, _, files in os.walk(folder_path):
                for file in files:
                    if extension_filter:
                        if any(file.endswith(ext) for ext in extension_filter):
                            matching_files.append(os.path.join(root, file))
                    else:
                        matching_files.append(os.path.join(root, file))
            return matching_files

        def create_speaker(self, audio, transcript: str):
            words = self.ctc.align(audio, transcript)
            full_codes = self.audio_codec.encode(
                self.audio_codec.convert_audio_tensor(
                    audio=torch.cat([i[\"audio\"] for i in words], dim=1),
                    sr=self.ctc.sample_rate
                ).to(self.audio_codec.device)
            ).tolist()
            data = []
            start = 0
            for i in words:
                end = int(round((i[\"x1\"] / self.ctc.sample_rate) * 75))
                word_tokens = full_codes[0][0][start:end]
                start = end
                if not word_tokens:
                    word_tokens = [1]
                data.append({
                    \"word\": i[\"word\"],
                    \"duration\": round(len(word_tokens) / 75, 2),
                    \"codes\": word_tokens
                })
            return {
                \"text\": transcript,
                \"words\": data,
            }

        def save_batch(self):
            if not self.current_batch:
                return
            os.makedirs(self.save_dir, exist_ok=True)
            path = os.path.join(self.save_dir, f\"{self.save_id:06d}.parquet\")
            logger.info(f\"Saving data: {path}\")
            pl.DataFrame(self.current_batch).write_parquet(path)
            self.current_batch = []
            self.save_id += 1

        def run(self):
            for i in self.files:
                try:
                    df = pl.read_parquet(i)
                except Exception as e:
                    logger.error(f\"Error reading parquet file {i}: {e}\")
                    continue

                for data in tqdm(df.iter_rows(named=True), total=len(df)):
                    try:
                        transcript = data['transcript']
                        audio = io.BytesIO(data['audio']['bytes'])
                        speaker = self.create_speaker(audio, transcript)
                        prompt = self.prompt_processor.get_training_prompt(speaker)
                        self.current_batch.append({'prompt': prompt})
                        
                        self.items_processed += 1
                        if self.items_processed % self.save_frequency == 0:
                            self.save_batch()
                    except ValueError as e:
                        logger.warning(f\"Value error in data processing: {e}\")
                    except IOError as e:
                        logger.error(f\"IO error in data processing: {e}\")
                    except Exception as e:
                        logger.critical(f\"Unexpected error in data processing: {e}\")

            if self.current_batch:
                self.save_batch()

    # Example usage
    data_creator = DataCreation(
        model_tokenizer_path=\"path/to/model/tokenizer\",
        audio_files_path=\"path/to/audio/files\",
        save_dir=\"path/to/save/processed/data\",
        save_frequency=1000  # Adjust this value as needed
    )
    data_creator.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Model Training\n",
    "\n",
    "Now, we will fine-tune the OuteTTS model using the prepared dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from outetts import InterfaceHF, HFModelConfig\n",
    "\n",
    "# Define model configuration\n",
    "config = HFModelConfig(\n",
    "    model_path=\"OuteAI/OuteTTS-0.3-500M\",\n",
    "    language=\"fr\",\n",
    "    tokenizer_path=\"path/to/tokenizer\",\n",
    "    max_seq_length=4096,\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "# Initialize the model interface\n",
    "tts_interface = InterfaceHF(config)\n",
    "\n",
    "# Example training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in data_loader:\n",
    "        # Fine-tune the model with the batch data\n",
    "        tts_interface.train(batch)\n",
    "        # Save the model checkpoint\n",
    "        tts_interface.save_checkpoint(f\"checkpoint_{epoch}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model Evaluation\n",
    "\n",
    "Evaluate the fine-tuned model to ensure it performs well on French TTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example evaluation script\n",
    "from outetts import InterfaceHF, HFModelConfig\n",
    "\n",
    "# Define model configuration\n",
    "config = HFModelConfig(\n",
    "    model_path=\"path/to/fine-tuned/model\",\n",
    "    language=\"fr\",\n",
    "    tokenizer_path=\"path/to/tokenizer\",\n",
    "    max_seq_length=4096,\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "# Initialize the model interface\n",
    "tts_interface = InterfaceHF(config)\n",
    "\n",
    "# Example evaluation\n",
    "text = \"Bonjour, comment Ã§a va?\"\n",
    "output = tts_interface.generate(text)\n",
    "output.save(\"output.wav\")\n",
    "\n",
    "# Play the generated audio\n",
    "import IPython.display as ipd\n",
    "ipd.Audio(\"output.wav\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
